## 设计原则
- 高性能（硬件适应，图优化，并发）
- 易开发（算法封装算子）
- 可移植（异构系统，设备）

## 机制设计
### 自动求导

1. 手动求解法：动用链式法则求解出梯度公式，代入数值，得到最终梯度值
2. 数值求导法：一开始直接代入数值近似求解
3. 符号求导法：直接对代数表达式求解，最后才代入问题 数字
4. 自动求导法（自动微分）
>介于23之间。
>1. 对基本算子符号求导
>2. 带入数值，保留中间结果
>3. 应用于整个函数
>利用了计算图记录了每一步基本运算的中间结果这一优势，逐个算子自后向前计算梯度。

### 检查点机制
- TensorFlow 通过向计算图中插入Save 节点及其关联节点来完成保存模型的功能
- 在恢复模型时，也是通过在计算图中插入Restore节点及其关联节点来完成

### TensorFlow中的控制流
>**tensorflow控制流的设计原则是通过引入最少的控制模块，利用这些控制模块可以表示很多复杂应用广泛的控制过程。**

些控制模块还能够适应并发，分布式运算，同时能够实现自动微分。
在Tensorflow中，每一个操作都会在一个执行帧中被 执行，控制流操作负责创建和管理这些执行帧
eg
![[Pasted image 20231101173550.png]]

Tensorflow中的控制流和优化器 https://zhuanlan.zhihu.com/p/270559504
### 计算图的执行模式

![[Pasted image 20231101184330.png]]
![[Pasted image 20231101184520.png]]

### 计算图本地执行
#### 剪枝：得到本地运行的最小子图
- 去除与输出节点无关的边与点
- 为输入输出建立与外界的交互
#### 分配：节点与计算设备的对应
eg：贪心算法

#### 优化：
>1. 通过图优化，可以根据不同的硬件结构调整计算调度策略，从 而获得更快的计算速度和更高的硬件利用率
>2. 也能减少推断过程中所需的峰值内存，从而运行更大的模型

- 常量折叠：有的常数节点可以被提前计算，用得到的结果生成新的节点 来代替原来的常数节点（eg：const链接提前计算，同态表达式......)
- 算术优化：公共表达式消除，算术简化（eg：结合律，交换律）
- 布局优化：两个连续的GPU计算 节点之间的连续 NCHW2NHWC 和 NHWC2NCHW 转换应互相抵消去除
- 重映射：算子融合，将出现频率较高的子图用一个单独算子来替代， 提高计算效率

### 计算图分布式执行
- 通信机制：点到点 or 集合通信
- 容错机制：同步相关，错误检测


## 系统实现及执行流
ps：详见 《智能计算系统》第五章

![[Pasted image 20231101185930.png]]

![[Pasted image 20231101190010.png]]

![[Pasted image 20231101190036.png]]