{
	"nodes":[
		{"id":"a54cb9dcb61f1ba3","type":"text","text":"内存瓶颈","x":-615,"y":-120,"width":135,"height":60},
		{"id":"17214681fe900f63","type":"text","text":"DNN中三个key observations","x":-439,"y":-120,"width":259,"height":60},
		{"id":"d8c6d9cbe877553f","type":"text","text":"计算分层，在多迭代中保持不变","x":-90,"y":-120,"width":250,"height":60},
		{"id":"a645a988390528f3","type":"text","text":"同一时间只能计算一层，但要保存所有层（反向传播）","x":-90,"y":-21,"width":250,"height":60},
		{"id":"fb546f8847ad5bac","type":"text","text":"SGD(随机梯度下降)，多层","x":-90,"y":-220,"width":250,"height":60},
		{"id":"fd1e95f67dfe6762","type":"text","text":"overprovision（超额供应）\n中间feature map分配存储到内存中但要等待很长时间才被利用，内存利用率很低","x":223,"y":-190,"width":217,"height":120},
		{"id":"0b2e2bd8fd673f02","type":"text","text":"vDNN : conservatively allocate for maximum memory usage","x":206,"y":129,"width":250,"height":60},
		{"id":"c0abaf920546dd50","type":"file","file":"论文阅读/vDNN/Pasted image 20231025152121.png","x":440,"y":-178,"width":216,"height":116},
		{"id":"ff4452e98793499c","type":"text","text":"网络图不一定完全线性，要甄别哪些feature map可以offload","x":-586,"y":280,"width":270,"height":101},
		{"id":"33dc02807f10b122","type":"text","text":"dataflow graph数据流图明确依赖\n\n仅图末端（出度=0）可以offload","x":-586,"y":611,"width":270,"height":100},
		{"id":"a9a15ad9c14ac4fc","type":"file","file":"论文阅读/vDNN/Pasted image 20231025152037.png","x":-586,"y":444,"width":270,"height":167},
		{"id":"5eb6ff06cb100f63","type":"file","file":"论文阅读/vDNN/Pasted image 20231025152441.png","x":-600,"y":711,"width":299,"height":120},
		{"id":"b749c9996bca390a","type":"text","text":"反向传播过程中按需swapin会导致串行，增加开销","x":-161,"y":305,"width":250,"height":60},
		{"id":"367f4e8d06dd356e","type":"text","text":"prefetch，将交换时间与上n层的计算重合，隐藏开销","x":-155,"y":453,"width":250,"height":60},
		{"id":"1355312b4847cca0","type":"text","text":"积极释放内存，尤其feature map。\n后续需要重用的内存swap（offload）到CPU中。","x":-225,"y":114,"width":385,"height":90,"color":"1"},
		{"id":"1ae83591c7a070ec","type":"text","text":"vDNN设计内存操作，如何处理cudaMalloc() or cudaFree()中的同步陷阱。","x":206,"y":305,"width":250,"height":76},
		{"id":"ee55a132d09ac499","type":"text","text":"vDNN pool，一次分配，自己管理 malloc与free。","x":205,"y":460,"width":250,"height":60},
		{"id":"1d83e6ebdeabe551","type":"file","file":"论文阅读/vDNN/Pasted image 20231025155616.png","x":-234,"y":513,"width":400,"height":221},
		{"id":"446e5711e6e736f0","type":"text","text":"预取太早：内存浪费\n预取太晚：增加延时\n\n“carefully designed the vDNN prefetch”：取最近的（已offload未prefetch）将要用到的层","x":-159,"y":771,"width":339,"height":129},
		{"id":"22691a7c4f048301","type":"file","file":"论文阅读/vDNN/Pasted image 20231025160143.png","x":-189,"y":900,"width":400,"height":204},
		{"id":"98f3bece1e09429f","type":"text","text":"which layers to offload","x":548,"y":313,"width":250,"height":60},
		{"id":"87b66f00c695b560","type":"text","text":"1. 显存大小\n2. 卷积算法及其每层内存使用\n3. 网络带宽性能","x":543,"y":417,"width":255,"height":123},
		{"id":"f2825ad916022892","type":"text","text":"性能与内存占用的trade off，所用data都offload将会导致极低性能","x":880,"y":300,"width":281,"height":87},
		{"id":"d6ce0c9840ecc01a","type":"text","text":"heuristic-based memory transfer policies","x":798,"y":653,"width":252,"height":81},
		{"id":"2a0f19516999950b","type":"text","text":"Static vDNN","x":475,"y":822,"width":250,"height":60},
		{"id":"5b9481c10a225f0c","type":"text","text":"vDNNall：offload所有\n节省内存最多，性能最拉","x":340,"y":972,"width":250,"height":60},
		{"id":"6532c16c3ce327c8","type":"text","text":"vDNNconv：只offload卷积层\n性能更好(卷积层计算较慢，更能隐藏swap开销)","x":624,"y":969,"width":272,"height":90},
		{"id":"a3cfc520f2bcf131","type":"text","text":"Dynamic vDNN","x":1140,"y":822,"width":250,"height":60},
		{"id":"0c635f659a902921","type":"text","text":"1.run vDNNall : 确定是否有可能运行（该方法所需内存最小）\n2.采用最快算法 without offload:（性能最好）如果可以运行，选取该方法。\nelse run with vDNNconv ，如果可以，选择该方法\nelse run with vDNNall，如果可以，选择该方法。\n3.采用贪心算法，每层检测2中步骤，若最快算法不可行，更换慢但内存占用小的算法。","x":1065,"y":972,"width":400,"height":236},
		{"id":"1dd5e467173d0dec","type":"text","text":"不能保证优化最优，但已经很好了！","x":1140,"y":1280,"width":250,"height":60},
		{"id":"05812d712be4b2fa","type":"file","file":"论文阅读/Capuchin Tensor-based GPU Memory Management for Deep Learning/Capuchin.canvas","x":1660,"y":1110,"width":400,"height":400}
	],
	"edges":[
		{"id":"bb21d94f5e2ab86b","fromNode":"a54cb9dcb61f1ba3","fromSide":"right","toNode":"17214681fe900f63","toSide":"left"},
		{"id":"2afacea3d380d34e","fromNode":"17214681fe900f63","fromSide":"right","toNode":"fb546f8847ad5bac","toSide":"left"},
		{"id":"f5a2db714ab35c05","fromNode":"17214681fe900f63","fromSide":"right","toNode":"d8c6d9cbe877553f","toSide":"left"},
		{"id":"1a93039422c5da6d","fromNode":"17214681fe900f63","fromSide":"right","toNode":"a645a988390528f3","toSide":"left"},
		{"id":"d467f6a6d8c08b64","fromNode":"fb546f8847ad5bac","fromSide":"bottom","toNode":"d8c6d9cbe877553f","toSide":"top"},
		{"id":"38d87f70ed8290e4","fromNode":"d8c6d9cbe877553f","fromSide":"bottom","toNode":"a645a988390528f3","toSide":"top"},
		{"id":"1da775acc39efa38","fromNode":"a645a988390528f3","fromSide":"right","toNode":"fd1e95f67dfe6762","toSide":"left"},
		{"id":"a99ca8cf0960f413","fromNode":"fd1e95f67dfe6762","fromSide":"bottom","toNode":"0b2e2bd8fd673f02","toSide":"top"},
		{"id":"29a8f71804910b52","fromNode":"0b2e2bd8fd673f02","fromSide":"left","toNode":"1355312b4847cca0","toSide":"right"},
		{"id":"eade9a1c0146978f","fromNode":"1355312b4847cca0","fromSide":"left","toNode":"ff4452e98793499c","toSide":"right"},
		{"id":"1ceee08d83b8e6f1","fromNode":"ff4452e98793499c","fromSide":"left","toNode":"33dc02807f10b122","toSide":"left"},
		{"id":"6d0b07d05f966c53","fromNode":"1355312b4847cca0","fromSide":"bottom","toNode":"b749c9996bca390a","toSide":"top"},
		{"id":"e5df8e7a3ed1e754","fromNode":"b749c9996bca390a","fromSide":"bottom","toNode":"367f4e8d06dd356e","toSide":"top"},
		{"id":"28a3b7a5a603116e","fromNode":"1355312b4847cca0","fromSide":"right","toNode":"1ae83591c7a070ec","toSide":"left"},
		{"id":"d2882c5f12a83e9b","fromNode":"1ae83591c7a070ec","fromSide":"bottom","toNode":"ee55a132d09ac499","toSide":"top"},
		{"id":"32bfff91a63d4188","fromNode":"1d83e6ebdeabe551","fromSide":"top","toNode":"446e5711e6e736f0","toSide":"top"},
		{"id":"5a92b8c0843ce83a","fromNode":"1355312b4847cca0","fromSide":"right","toNode":"98f3bece1e09429f","toSide":"top"},
		{"id":"37238455aca3bbb9","fromNode":"98f3bece1e09429f","fromSide":"right","toNode":"f2825ad916022892","toSide":"left"},
		{"id":"57ef12a681353972","fromNode":"98f3bece1e09429f","fromSide":"bottom","toNode":"87b66f00c695b560","toSide":"top"},
		{"id":"4b454b91b33731ce","fromNode":"f2825ad916022892","fromSide":"bottom","toNode":"d6ce0c9840ecc01a","toSide":"top"},
		{"id":"74e9cc48bcfad77b","fromNode":"87b66f00c695b560","fromSide":"right","toNode":"d6ce0c9840ecc01a","toSide":"top"},
		{"id":"223241a32f225c48","fromNode":"d6ce0c9840ecc01a","fromSide":"bottom","toNode":"a3cfc520f2bcf131","toSide":"top"},
		{"id":"d581f8bb144adc1e","fromNode":"d6ce0c9840ecc01a","fromSide":"bottom","toNode":"2a0f19516999950b","toSide":"top"},
		{"id":"1b0568238a66502c","fromNode":"2a0f19516999950b","fromSide":"bottom","toNode":"5b9481c10a225f0c","toSide":"top"},
		{"id":"60347c3813e61d99","fromNode":"2a0f19516999950b","fromSide":"bottom","toNode":"6532c16c3ce327c8","toSide":"top"},
		{"id":"69993c688e321eac","fromNode":"2a0f19516999950b","fromSide":"right","toNode":"a3cfc520f2bcf131","toSide":"left","label":"未考虑带宽，卷积算法等因素"},
		{"id":"889fb58447461abd","fromNode":"a3cfc520f2bcf131","fromSide":"bottom","toNode":"0c635f659a902921","toSide":"top"},
		{"id":"78bd62b193e9cf68","fromNode":"0c635f659a902921","fromSide":"bottom","toNode":"1dd5e467173d0dec","toSide":"top"},
		{"id":"8506578d1ae48cda","fromNode":"1dd5e467173d0dec","fromSide":"right","toNode":"05812d712be4b2fa","toSide":"left","label":"更多的优化空间"}
	]
}